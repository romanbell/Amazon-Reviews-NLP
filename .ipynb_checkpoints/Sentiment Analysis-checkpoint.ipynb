{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-49c9ccb2521f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNLTK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://realpython.com/sentiment-analysis-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('train.csv', header=None, names=['Rating', 'Title', 'Review'])\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Tokenization (sentence vs word tokenization)\n",
    "- Tokenize each element in 'review' column\n",
    "- Filter out symbols\n",
    "- Filter out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = training_df['Review'].loc[0]\n",
    "t1 = training_df['Review'].loc[1]\n",
    "t2 = training_df['Review'].loc[2]\n",
    "t3 = training_df['Review'].loc[3]\n",
    "t4 = training_df['Review'].loc[4]\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(t0)\n",
    "\n",
    "token_list = []\n",
    "for token in doc:\n",
    "    #remove stop words\n",
    "    token_list.append(token)\n",
    "\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token_list = []\n",
    "for token in token_list:\n",
    "    if not token.is_stop:\n",
    "        filtered_token_list.append(token)\n",
    "        \n",
    "filtered_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Normalization\n",
    "- Stemming vs Lemmatization\n",
    "- Normalize each element in 'reviews' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Vectorization\n",
    "- Vectorize each token of 'reviews' \n",
    "- Save vectorized reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Classification\n",
    "- Create classifier for vectorized data\n",
    "- TensorFlow (Google, more DIY, more customizable/complex, bit more powerful with steeper learning curve)\n",
    "- PyTorch (Facebook's version of TF, comperable to tf, apparently it's slightly easier to pick up)\n",
    "- Scikit Learn (Extremely simple in comparison to tf and pytorch) \n",
    "- spaCy also has a text classifier if we want to use that \n",
    "- \n",
    "    #### 5.1\n",
    "    - Split into training/test sets\n",
    "    - Likely 80/20\n",
    "- \n",
    "    #### 5.2\n",
    "    - Model selection\n",
    "- \n",
    "    #### 5.3\n",
    "    - Train model\n",
    "- \n",
    "    #### 5.4\n",
    "    - Evaluate performance\n",
    "- \n",
    "    #### 5.5\n",
    "    - Tweak parameters\n",
    "    - Potentially include hyperparameters\n",
    "- \n",
    "    #### 5.6\n",
    "    - Generate predictions\n",
    "    - Vector from (-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
