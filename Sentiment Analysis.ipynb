{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import spacy\n",
    " \n",
    "from langdetect import detect\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "# matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'pgf.rcfonts': False,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://realpython.com/sentiment-analysis-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk dependency\n",
    "# python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('train.csv', header=None, names=['Rating', 'Title', 'Review'])\n",
    "testing_df = pd.read_csv('test.csv', header=None, names=['Rating', 'Title', 'Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5: Remove Non-English Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "    - Try to get this to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  en\n",
      "Language:  fr\n"
     ]
    }
   ],
   "source": [
    "print(\"Language: \", detect('Hello, simple english review because I like reviewing products in english!'))\n",
    "print(\"Language: \", detect('Avez-vous déjà vu un CD double et un DVD avec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['Language'] = detect(str(training_df['Review']))\n",
    "testing_df['Language'] = detect(str(testing_df['Review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_english_mask = (training_df['Language'] == 'en')\n",
    "training_df = training_df[non_english_mask]\n",
    "\n",
    "non_english_mast = (testing_df['Language'] == 'en')\n",
    "testing_df = testing_df[non_english_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(training_df['Rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdflatex\n",
    "from matplotlib.backends import backend_pgf\n",
    "# matplotlib.use('pgf')\n",
    "# plt.rc('pgf', texsystem='pdflatex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Total Ratings - Training')\n",
    "training_df['Rating'].value_counts().plot.bar()\n",
    "# plt.savefig('Ratings Distribution.png')\n",
    "# plt.savefig('Ratings Distribution.pgf', format = 'pgf')\n",
    "plt.savefig('Ratings Distribution.pdf')\n",
    "\n",
    "\n",
    "# import tikzplotlib\n",
    "# tikzplotlib.save(\"Ratings Distribution.tex\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_df['Rating'].value_counts().plot.bar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Length of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Length of Review Characters\")\n",
    "testing_df['Review'].str.len().plot.hist(bins = 10)\n",
    "plt.xticks(np.linspace(0, 1000, 11))\n",
    "# plt.savefig('Review Length Hist.png')\n",
    "plt.savefig('Review Length Hist.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2: Tokenization (sentence vs word tokenization)\n",
    "- Tokenize each element in 'review' column\n",
    "- Filter out symbols\n",
    "- Filter out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This model may be ok for sedentary types but Im active and get around alot in my job  consistently found these stockings rolled up down by my ankles Not Good Solution go with the standard compression stocking 2030 stock 114622 Excellent support stays up and gives me what I need Both pair of these also tore as I struggled to pull them up all the time Good riddancebad investment '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    result_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return result_text\n",
    "\n",
    "s = r'This model may be ok for sedentary types, but I\\'m active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment! '\n",
    "remove_punc(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This model may be ok for sedentary types but Im active and get around alot in my job  consistently found these stockings rolled up down by my ankles Not Good Solution go with the standard compression stocking  stock  Excellent support stays up and gives me what I need Both pair of these also tore as I struggled to pull them up all the time Good riddancebad investment '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_nums(text):\n",
    "    result_text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return result_text\n",
    "\n",
    "remove_nums(remove_punc(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This model may be ok for sedentary types but Im active and get around alot in my job consistently found these stockings rolled up down by my ankles Not Good Solution go with the standard compression stocking stock Excellent support stays up and gives me what I need Both pair of these also tore as I struggled to pull them up all the time Good riddancebad investment '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_spaces(text):\n",
    "    result_text = re.sub(' +', ' ', text)\n",
    "    return result_text\n",
    "\n",
    "remove_spaces(remove_nums(remove_punc(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this model may be ok for sedentary types but im active and get around alot in my job consistently found these stockings rolled up down by my ankles not good solution go with the standard compression stocking stock excellent support stays up and gives me what i need both pair of these also tore as i struggled to pull them up all the time good riddancebad investment '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_spaces(remove_nums(remove_punc(s))).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_stop_words runtime:  0:00:00.789076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model ok sedentary types m active alot job consistently found stockings rolled ankles good solution standard compression stocking stock excellent support stays gives need pair tore struggled pull time good riddancebad investment'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stop_words(text):\n",
    "\n",
    "    r_start_time = datetime.datetime.now()\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    text_list = nlp(text)\n",
    "    \n",
    "#     stop_list = ['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not',\n",
    "#                  'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', \n",
    "#                  'will', 'with']\n",
    "    \n",
    "    temp_list = []\n",
    "    for token in text_list:\n",
    "        if not token.is_stop:\n",
    "            temp_list.append(token)\n",
    "    \n",
    "    str_output = ' '.join([str(elem) for elem in temp_list])\n",
    "\n",
    "    r_end_time = datetime.datetime.now()\n",
    "#     print('remove_stop_words runtime: ', r_end_time - r_start_time)\n",
    "    \n",
    "    return str_output    \n",
    "    \n",
    "remove_stop_words(remove_spaces(remove_nums(remove_punc(s))).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_nltk(text):\n",
    "#     r_start_time = datetime.datetime.now()\n",
    "    \n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.append('play')\n",
    "\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "    str_output = ' '.join([str(elem) for elem in tokens_without_sw])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     r_end_time = datetime.datetime.now()\n",
    "#     print('\\n Runtime: ', r_end_time - r_start_time)\n",
    "    \n",
    "#     print(str_output)\n",
    "    return(str_output)\n",
    "    \n",
    "# remove_stop_words_nltk(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Normalization (Root Word Extraction)\n",
    "- Stemming vs Lemmatization\n",
    "- Normalize each element in 'reviews' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Lemmatization:        The striped bats are hanging on their feet\n",
      "\n",
      "After Simple Lemmatization:  The striped bat are hanging on their foot\n",
      "\n",
      "After POS Lemmatization:     The strip bat be hang on their foot\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize_sentence_simple(sentence):\n",
    "    \n",
    "    temp_list = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        temp_list.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    \n",
    "    return ' '.join([str(elem) for elem in temp_list])\n",
    "\n",
    "\n",
    "def lemmatize_sentence_pos(sentence):\n",
    "    \n",
    "    temp_list = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        temp_list.append(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
    "#         temp_list.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    \n",
    "    return ' '.join([str(elem) for elem in temp_list])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word = 'feet'\n",
    "# print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
    "\n",
    "\n",
    "sentence = \"The striped bats are hanging on their feet\"\n",
    "\n",
    "print(\"Before Lemmatization:       \", sentence)\n",
    "print(\"\\nAfter Simple Lemmatization: \", lemmatize_sentence_simple(sentence))\n",
    "print(\"\\nAfter POS Lemmatization:    \", lemmatize_sentence_pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def preprocess\n",
    "    # output list = []\n",
    "    # for element in row\n",
    "        # text = row's text\n",
    "        # output text = remove_punctuation(text)\n",
    "        # output text = remove_numbers(output text)\n",
    "        # output text = lowercase(output text)\n",
    "        # output text = remove_stop words(output text)\n",
    "        # output list.append(output text )\n",
    "    # return output list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.00%\n",
      "40.00%\n",
      "60.00%\n",
      "80.00%\n",
      "100.00%\n",
      "POS Lemma, total items:  50000 \n",
      "Runtime:  0:30:39.555161\n"
     ]
    }
   ],
   "source": [
    "# Parsing\n",
    "\n",
    "def process_column(unprocessed_list, total_items):\n",
    "    output_list = []\n",
    "    count = 0\n",
    "    for item in unprocessed_list:\n",
    "        if item != ' ':            \n",
    "            #No Lemma\n",
    "#             output_list.append( remove_nums(remove_punc(remove_stop_words_nltk(item))).lower()  )\n",
    "\n",
    "\n",
    "            #Simple\n",
    "#             output_list.append( remove_nums(remove_punc(lemmatize_sentence_simple(remove_stop_words_nltk(item)))).lower()  )\n",
    "\n",
    "        \n",
    "            #POS\n",
    "            output_list.append( remove_nums(remove_punc(lemmatize_sentence_pos(remove_stop_words_nltk(item)))).lower()  )\n",
    "        \n",
    "        else:\n",
    "            output_list.append(' ')\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 10000 == 0:\n",
    "            print(\"{:.2%}\".format(count / total_items))\n",
    "        \n",
    "    return output_list\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "total_items = 50000\n",
    "test_raw_reviews = testing_df['Review'].tolist()\n",
    "test_processed_reviews = process_column(test_raw_reviews[:total_items], total_items)\n",
    "\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"POS Lemma, total items: \", total_items, \"\\nRuntime: \", end_time - start_time)\n",
    "# print('with POS lemma: 0:01:17.570621')\n",
    "# print('Lemma W/o POS: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Review 1 ----------\n",
      "Raw:  This model may be ok for sedentary types, but I'm active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment! \n",
      "\n",
      "\n",
      "Processed:  this model may ok sedentary type  i m active get around alot job  consistently found stocking roll ankle  not good   solution  go standard compression stock    stock    excellent support  stay give i need  both pair also tore i struggle pull time  good riddancebad investment \n",
      "\n",
      "\n",
      "---------- Review 2 ----------\n",
      "Raw:  I bought one of these chargers..the instructions say the lights stay on while the battery charges...true. The instructions doNT say the lights turn off when its done. Which is also true. 24 hours of charging and the lights stay on. I returned it thinking I had a bad unit.The new one did the same thing. I just kept it since it does charge...but the lights are useless since they seem to always stay on. It's a \"backup\" charger for when I manage to drain all my AAs but I wouldn't want this as my only charger. \n",
      "\n",
      "\n",
      "Processed:  i bought one chargersthe instruction say light stay battery charge  true  the instruction dont say light turn do  which also true   hour charge light stay  i return think i bad unitthe new one thing  i kept since charge  light useless since seem always stay  it s  backup  charger i manage drain aas i would nt want charger \n"
     ]
    }
   ],
   "source": [
    "print('---------- Review 1 ----------')\n",
    "print('Raw: ', test_raw_reviews[0], '\\n\\n')\n",
    "print('Processed: ', test_processed_reviews[0])\n",
    "print('\\n')\n",
    "print('---------- Review 2 ----------')\n",
    "print('Raw: ', test_raw_reviews[2], '\\n\\n')\n",
    "print('Processed: ', test_processed_reviews[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "    - Remove single character tokens (i.e. 'a' or 'i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Vectorization\n",
    "- Vectorize each token of 'reviews' \n",
    "- Save vectorized reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame()\n",
    "sample_df['Targets'] = testing_df['Rating'].tolist()[:total_items]\n",
    "sample_df['Processed Text'] = test_processed_reviews\n",
    "print(\"only first\", total_items, \"samples of validation data\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "    - Use from gensim.models import word2vec\n",
    "    - Try to compare results withthe Keras Tokenizer and Keras Pad_Sequences modules \n",
    "    - Obviously select best from these\n",
    "    - Here ultimate goal is to obtain an array (1, 100) shape, then put this into a df with the true label\n",
    "    - Then use PCA to reduce 100 dimensions to 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, split=\" \")\n",
    "tokenizer.fit_on_texts(sample_df['Processed Text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(sample_df['Processed Text'].values)\n",
    "X = pad_sequences(X) # padding our text vector so they all have the same length\n",
    "\n",
    "y = sample_df['Targets'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(sample_df['Targets']).values\n",
    "# [print(sample_df['Targets'][i], y[i]) for i in range(0,15)]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "    - Use PCA or maybe a different dimensionality reduction technique to get a 1,2 input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "    - After PCA plot the output values and label each class with a certain color to determine if the data is linearly seperable (it shouldn't be) \n",
    "    - Also u can use T-SINE from sklearn to scatterplot certain wrods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Classification\n",
    "- Create classifier for vectorized data\n",
    "- TensorFlow (Google, more DIY, more customizable/complex, bit more powerful with steeper learning curve)\n",
    "- PyTorch (Facebook's version of TF, comperable to tf, apparently it's slightly easier to pick up)\n",
    "- Scikit Learn (Extremely simple in comparison to tf and pytorch) \n",
    "- spaCy also has a text classifier if we want to use that \n",
    "- \n",
    "    #### 5.1\n",
    "    - Split into training/test sets\n",
    "    - Likely 80/20\n",
    "- \n",
    "    #### 5.2\n",
    "    - Model selection\n",
    "- \n",
    "    #### 5.3\n",
    "    - Train model\n",
    "- \n",
    "    #### 5.4\n",
    "    - Evaluate performance\n",
    "- \n",
    "    #### 5.5\n",
    "    - Tweak parameters\n",
    "    - Potentially include hyperparameters\n",
    "- \n",
    "    #### 5.6\n",
    "    - Generate predictions\n",
    "    - Vector from (-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 256, input_length=X.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 4\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"{:.2%}\".format(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "[print('Text: ', sample_df['Processed Text'][i], '\\nPredicted Output: ', predictions[i], '\\nTrue Classification: ', y_test[i], '\\n\\n') for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "    - INclude sklearn metrics (Accuracy & F1)\n",
    "    - Other Algos (Random Forest maybe) \n",
    "    - Thicccccccc confusio matrix (before & after cross validation)\n",
    "    - Cross Validation\n",
    "    - Plot Learning Rate vs Loss somehow (look at the repo with the lm model)\n",
    "    - Figure out how to compare simple ML model (i.e. DT) vs ANN model (i.e. RNN or something else) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with sample review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_review = 'This is the best water bottle I have ever used. I love that it is BPA free and great on the environment. I think that everyone who is looking for a good water bottle should buy this one, it is absolutley perfect and totally what I am looking for. I love it!'\n",
    "dummy_review = 'I absolutley love this product, it is everything that I expected. The quality is unbeatable for the price. This product is amazing. I could not reccomend this product more!'\n",
    "dummy_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_processed = [remove_nums(remove_punc(remove_stop_words(dummy_review))).lower()]\n",
    "dummy_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape to correct input size \n",
    "\n",
    "dummy_vectorized = tokenizer.texts_to_sequences(dummy_processed)\n",
    "dummy_vectorized = np.concatenate( ( np.zeros((1, (len(X[0]) - len(dummy_vectorized[0]))))[0]  , (dummy_vectorized[0]) )  )\n",
    "dummy_vectorized = np.asarray(dummy_vectorized)\n",
    "dummy_vectorized = np.expand_dims(dummy_vectorized, axis = 0)\n",
    "dummy_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dummy_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
